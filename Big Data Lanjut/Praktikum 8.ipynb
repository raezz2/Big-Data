{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP47ikAavw5wWYNc2gYngzV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l_Nx8lC9NMfo","executionInfo":{"status":"ok","timestamp":1670292932723,"user_tz":-420,"elapsed":55220,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}},"outputId":"4170ed59-b399-4515-f3e8-76a0d80adc66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 53.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=a9ecd07662fdad11b336859da672ae0c272706838fb45359118a4cf2a700925a\n","  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"]}],"source":["!pip install pyspark\n"]},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.getOrCreate()\n","sc = spark.sparkContext"],"metadata":{"id":"10f7NNfxRIHc","executionInfo":{"status":"ok","timestamp":1670293805257,"user_tz":-420,"elapsed":9338,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n","\n","sentenceData = spark.createDataFrame([\n","    (0.0, \"Hi I heard about Spark\"),\n","    (0.0, \"I wish java could use case classes\"),\n","    (1.0, \"Logistic regression models are neat\")\n","], [\"label\", \"sentence\"])\n","\n","tokenizer = Tokenizer (inputCol=\"sentence\", outputCol=\"words\")\n","wordsData = tokenizer.transform(sentenceData)\n","\n","hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n","featurizedData = hashingTF.transform(wordsData)\n","\n","idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n","idfModel = idf.fit(featurizedData)\n","rescaledData = idfModel.transform(featurizedData)\n","\n","rescaledData.select(\"label\", \"features\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0yoDV702OG-j","executionInfo":{"status":"ok","timestamp":1670294131239,"user_tz":-420,"elapsed":7050,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}},"outputId":"9f1707f3-5ce1-41cd-ee0b-a38a471ca340"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+--------------------+\n","|label|            features|\n","+-----+--------------------+\n","|  0.0|(20,[6,8,13,16],[...|\n","|  0.0|(20,[0,2,7,13,15,...|\n","|  1.0|(20,[3,4,6,11,19]...|\n","+-----+--------------------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.ml.feature import Word2Vec\n","\n","documentDF = spark.createDataFrame([\n","    (\"Hi I heard about Spark\".split(\" \"), ),\n","    (\"I wish java could use case classes\".split(\" \"), ),\n","    (\"Logistic regression models are neat\".split(\" \"), )\n","], [\"text\"])\n","\n","word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n","model = word2Vec.fit(documentDF)\n","\n","result = model.transform(documentDF)\n","for row in result.collect():\n","  text, vector = row\n","  print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DERINi4KT9E-","executionInfo":{"status":"ok","timestamp":1670295870475,"user_tz":-420,"elapsed":2300,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}},"outputId":"ee462b5e-b750-40b6-c55e-cd855b8cee50"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Text: [Hi, I, heard, about, Spark] => \n","Vector: [-0.02300390750169754,-0.06358029544353486,0.0037466228008270265]\n","\n","Text: [I, wish, java, could, use, case, classes] => \n","Vector: [0.01459998737222382,-0.026636907165603976,-0.0360073766538075]\n","\n","Text: [Logistic, regression, models, are, neat] => \n","Vector: [-0.012251960672438146,0.0005856143310666084,0.0076403886079788215]\n","\n"]}]},{"cell_type":"code","source":["from pandas._libs.lib import fast_unique_multiple_list_gen\n","from pyspark.ml.feature import CountVectorizer\n","\n","df = spark.createDataFrame([\n","    (0, \"a b c\".split(\" \"))\n","], [\"id\", \"words\"])\n","\n","cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=3, minDF=2.0)\n","\n","model = cv.fit(df)\n","\n","result = model.transform(df)\n","result.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UH1lRkfeWRx2","executionInfo":{"status":"ok","timestamp":1670295395143,"user_tz":-420,"elapsed":903,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}},"outputId":"626d72a1-1451-4f38-e085-0f88228c2457"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------+---------+\n","|id |words    |features |\n","+---+---------+---------+\n","|0  |[a, b, c]|(0,[],[])|\n","+---+---------+---------+\n","\n"]}]},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.feature import HashingTF, Tokenizer\n","\n","training = spark.createDataFrame([\n","    (0, \"a b c d spark\", 1.0),\n","    (1, \"b d\", 0.0),\n","    (2, \"spark f g h\", 1.0),\n","    (3, \"hadoop mapreduce\",0.0),\n","],[\"id\", \"text\", \"label\"])\n","\n","tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n","hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=(\"features\"))\n","lr = LogisticRegression(maxIter=10, regParam=0.001)\n","pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n","\n","model = pipeline.fit(training)"],"metadata":{"id":"hdQj5rNnZJNX","executionInfo":{"status":"ok","timestamp":1670296502216,"user_tz":-420,"elapsed":10807,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["test = spark.createDataFrame([\n","    (4, \"spark i j k\"),\n","    (5, \"l m n\"),\n","    (6, \"spark hadoop spark\"),\n","    (7, \"apache hadoop\")\n","  ], [\"id\", \"text\"])\n","\n","prediction = model.transform(test)\n","# print (prediction.collect())\n","selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n","for row in selected.collect():\n","  rid, text, prob, prediction = row\n","  print(\"%d, %s) --> prob=%s, prediction=%f\" % (rid,text, str(prob), prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgXWzCKEbht_","executionInfo":{"status":"ok","timestamp":1670297404171,"user_tz":-420,"elapsed":522,"user":{"displayName":"MUHAMMAD REZZHA RIAMRIZAL ARSYA 22.21.1545","userId":"01634267351426795063"}},"outputId":"41e615a7-6532-4eab-8163-04529a51b522"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["4, spark i j k) --> prob=[0.5080831414127923,0.4919168585872077], prediction=0.000000\n","5, l m n) --> prob=[0.9851072999550657,0.01489270004493426], prediction=0.000000\n","6, spark hadoop spark) --> prob=[0.052589797035650615,0.9474102029643494], prediction=1.000000\n","7, apache hadoop) --> prob=[0.995626802321357,0.0043731976786429705], prediction=0.000000\n"]}]}]}